0	Привет, я Денис Гроцев из Спортмастера. Сейчас я буду ломать ваш мозг "невозможным параллельным алгоритмом".
Наша компания занимается спортивными товарами. Но чтобы продать что-нибудь полезное, сначала приходится привезти это на склад. Тут подключаемся мы, айтишники, и автоматизируем, автоматизируем... А чтобы работало быстрее, горизонтально масштабируем. Но это сложно, и чтобы решить проблему, сделаем обходной манёвр с фланга, зайдём в тыл, рассмотрим несколько вспомогательных примеров. 
1	Итак. Склад. Как он работает. Сначала на нём пусто. Приезжает машина и выгружает 230 коробок. Теперь на складе эти 230 коробок и есть.
Приходит кладовщик и увозит на тележке 100 коробок, туда столько помещается. Ещё приходит и увозит ещё тележку. Так и запишем: есть переменная текущего баланса, сначала 0. Пробегаемся по всем изменениям и добавляем их к балансу.
То же самое запишем на SQL, тут есть встроенный агрегат sum, удобно и идиоматично. А БД даже всё распараллелит под капотом.
То же самое запишем ещё компактнее и математично на Haskell.
Внимательно посмотрим, что такое параллельные вычисления, горизонтальная масштабируемость, Map Reduce. Пусть у нас есть мелкие задачи (тут они точками) и вычислительные узлы (3 штуки). Это могут быть процессоры или узлы кластера.
Скобками поделим задачи между узлами, например, поровну.
А можем поделить и каким-то другим способом. Но итоговый результат во всех случаях должен быть одинаковым. Это свойство проходят ещё в школе и называют ассоциативностью. Узел начинает вычисление с начального состояния. Ассоциативную операцию и начальное состояние вместе называют моноид. И это суть параллельности.
Вернёмся на склад и попытаемся погрузить ещё 100. Что получится? -70?
Нет, 0. В реальном мире не может быть отрицательных коробок на складе, овец в стаде и даже рублей в кошельке. А вот на карточке может. Отрицательные числа могут быть в обществе между людьми и обозначают долг. Алгоритм тут сбоит.
Не беда, исправим. Как только баланс стал отрицательным, заменим его на более реальный 0. Но тут каждый следующий шаг итерации зависит от предыдущего. C параллельностью проблема: не получится поделить на независимые куски и раздать вычислительным узлам.
С SQL тоже проблема - такого встроенного агрегата нет. Можно попробовать написать пользовательский агрегат - т.е. реализовать интерфейс в вашей любимой СУБД. Но он должен быть параллелизуемым.
В Haskell заменим обычный плюс на квадратный. Он обрезает негатив. Но и тут проблема - операция неассоциативна - скобки слева и справа дадут разное.
Нашли противоречие. Это конец! Надеюсь, я вас убедил, что распараллелить не получится? Может быть возникли какие-то вопросы? 
2	О! Видите, это не конец - это только начало! Включим машину времени и вернёмся на 10 000 лет назад, когда считали "один, два, много".
А на Ближнем Востоке в районе Плодородного Полумесяца первые скотоводы приручили овец. И встретились с проблемой.
Наступает ночь.
Просыпается мафия и ест овец. Какое решение? Поставить заборчик и загонять туда овец на ночь. Но всех ли овец загнали и можно идти спать или ещё несколько бегает по округе? Считать много не умеем - т.е. типичный highload - предел технологических возможностей. 
Какой-то мудрый скотовод придумал так. Утром, когда овца выходит из загона, он кладёт камень. Выходит другая - ещё камень. А вечером наоборот. Овца заходит - он камень убирает. Когда кучка пустая, можно идти спать.
Наступает ночь. Просыпаются волки. И уходят ни с чем. С точки зрения скотовода, камни магически связаны с овцами. Вспоминаем закон Кларка: любая достаточно развитая технология неотличима от магии.
Наверное, в математике есть какая-то магия? Да, в математике есть какая-то магия. И мы будем её придерживаться. 
3	Посмотрим на числа Фибоначчи. Помните, они начинаются с 0, 1.
А затем, каждое следующее - это сумма двух предыдущих. Объявляете две переменных и простым итеративным алгоритмом считаем за линейное время. А как насчёт посчитать за логарифмическое время?
Без проблем! Считаем, что состояние алгоритма - те две переменных - это вектор-строка. Следующее состояние - это тоже вектор.
А преобразование между ними, векторами - это матрица. Первый столбец означает, что мы копируем текущее число, а второй столбец, что складываем текущее и предыдущее числа. Например, начальное состояние (0, 1) умножаем на А, получаем следующее состояние (1, 1).
И т.д. получаем произвольную N-тую пару чисел Фибоначчи. Если присмотреться, мы просто начальное состояние N раз умножили на А. И задача свелась к эффективному нахождению N-той степени матрицы А.
Тоже не проблема. Представим N в двоичном виде. Число N - это N единичек. Тут они обозначены точками. Воспользуемся ассоциативностью и сгруппируем их скобками - каждая группа вдвое больше предыдущей. Некоторые группы могут оказаться пустыми, если в двоичном представлении число N в этом разряде стоит 0. Потом матрицу А умножим на себя - получим А в квадрате. Её ещё раз на себя - получим А в четвёртой. И т.д. все степени двойки. Потом перемножим те степени, где стоит единичка в двоичном представлении числа N. Всё это считается за логарифмическое время.
Заметим, что в матрице А 4 числа, а в результате только одно. Нужна процедура распаковки, которая забудет 3 числа. Но избыточная информация нужна, чтобы сделать вычисление ассоциативным и быстрым. Матрица с умножением будет моноидом. 
4	Среднее арифметическое двух чисел - это просто! Обозначим его круглым плюсом.
Но, если расставить скобки слева и справа, результат будет разным! Среднее арифметическое при попарном подсчёте неассоциативно. Тем не менее, БД как-то справляется, параллелит и даже есть встроенный агрегат. Что происходит?
А происходит то, что опять нужна дополнительная информация. Нужна структура с двумя полями - количество штук и общая сумма.
Два моноида А и В склеиваются покомпонентно: штуки со штуками, а суммы с суммами. А начальное состояние - когда нет ни штук, ни сумм.
Результат из моноида извлекается делением общей суммы на количество элементов. А параллельная реализация упаковывает  числа в моноид, прогоняет MapReduce и распаковывает результат из моноида. 
5	Наконец, возвращаемся к складу и проблеме, как параллельно считать неотрицательную сумму. Будет всё тоже самое, что в предыдущих примерах.
5.1	Но сперва, Группа Гротендика. Это всего лишь способ записать отрицательные числа без отрицательных чисел! Например, у нас в наличии только натуральные числа. Если нужно отнять одно число от другого, то результат может оказаться уже не натуральным. Но не будем ничего сокращать, пусть в структуре будет избыточность и будет 2 поля: вычитаемое и уменьшаемое, или падение и рост, или долг и наличность, называйте, как хотите. Для минус 2 будет бесчисленное множество представлений: пары (5, 3), (15, 13) и т.д. Просто.
5.2	Склад. Возьмём фиксированный кусок истории изменений склада. Хоть случайный. Например, расход 100, приход 50.
И посмотрим, что будет, когда прогоним его на разных начальных балансах. Для нуля получается 50 на выходе. Для 230 получается 180.
Т.е. в 1 строке эквивалентно истории +50. Во второй строке -50. Логики не видно.
Но если построим график для большего количества точек, заметим простую закономерность - ломаная прямая с одной точкой излома. То есть вся история изменений огромной длины сжимается в функцию только с 2 параметрами. И оно совпадает с представлением Гротендика.
Перепишем историю в форме Гротендика, в виде пар неотрицательных чисел.
Как склеивать два соседних куска истории? Как будто переставим скобки в середину, и сократим так, что в скобках будет одно число - рост или падение.
И то, что получилось, добавим к тому же цвету, налево или направо, смотря что получилось. Общая схема для А и В - серединка взаимно сокращается.
5.3	Наконец, реализация. Заводим структуру с двумя полями - падение и рост.
Упаковка числа в моноид смотрит на знак числа и помещает его в нужное поле. Т.е. отрицательный рост - это падение.
Чтобы склеить два состояния, находим сначала серединку С, а потом добавляем её влево и вправо к А и В.
Пустое состояние - это когда нет ни роста, ни падения.
А параллельная реализация такая же, как в среднем арифметическом - упаковываем числа в моноид, прогоняем MapReduce и распаковываем результат из моноида. Е-е! Параллельная реализация неотрицательной суммы существует!
5.4	Можно даже проверить юнит тестами. В две строчки! Одна говорит, что эффективная реализация делает то же, что и первоначальная. Вторая, что работают свойства моноида - ассоциативность и начальное состояние.
Но тесты показывают наличие ошибок, а не их отсутствие. Строгое доказательство основано на неочевидных свойствах максимума и минимума. Прям вот, совсем неочевидных!
Посмотрим 4 квадранта плоскости АВ по-отдельности – в каждом будет простое тождество. 
6	Мы в конце пути. Вспомним, как это было.
Сперва нам показалось, что неотрицательную сумму из реального мира невозможно распараллелить.
Но пример с Волшебными Камнями напомнил нам о законе Кларка и придал веру в магию математики.
Пример Фибоначчи показал, что нужна избыточная информация, чтобы сделать вычисление ассоциативным и эффективным.
Пример со Средним показал, что нужна не ассоциативность базовой операции, а ассоциативность моноида, который её оборачивает.
И наконец, мы вернулись к параллельному решению задачи.
Посмотрим, как можно действовать в общем случае. Чтобы считать параллельно, нужно найти моноид. Опять пять шагов:
Начать стоит с полного состояния последовательного алгоритма.
Затем в явном виде нужно построить функцию перехода между этими состояниями.
Третий шаг нам достаётся совершенно бесплатно, т.е. даром – математика гарантирует, что композиция функций ассоциативна.
Наконец, эту композицию функций нужно попытаться представить в компактной форме, где информации будет меньше, чем в полной истории. Это задача со звёздочкой и может не получиться. Тут уж как повезёт - не все алгоритмы можно распараллелить.
В итоге, получаем все плюшки красивого, идиоматичного и эффективного кода. В приложении есть полная реализация для Oracle и Java Stream, но это не Haskell и компактностью там и не пахнет. А без описания про моноиды не понятна магия нескольких строк. Можете теперь потролить коллег, попросив распараллелить цикл, а результатами поделиться со мной в телеграм.
